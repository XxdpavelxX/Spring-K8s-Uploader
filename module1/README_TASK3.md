### Task 3: Improvements
What would you add or change to make this a fully production ready application?

To make this into a fully production ready application there are several key considerations that we will have to take into account. 

** Reliable Hosting Infrastructure: ** Currently this application only runs on a local computer. This is not a reliable way to host applications for many reasons including resource limitation, security, reliability, observability, and monitoring constraints. For example we'll have to make several changes in the k8s-manifests file for this application to be production ready. Assuming we want to run on the cloud and not on prem, we'll first we'll have to change the ingress yaml to deploy a cloud LB such as AWS ALB (that's either public or private depending on our app reqs). It would also be good to modify the pvc to use more reliable volumes then those on the local worker node such as AWS EBS volumes.

** Infrastructure as Code: ** I would also create a separate teraform repo to spin up all the cloud resource that we would use to deploy this application. Such as Cloud managed k8s (ie AKS, EKS), multiple worker nodes hosted on the cloud (ie AWS EC2s), and reliable storage for our volumes (ie AWS EBS)

** CI/CD pipelines: ** I would create CI/CD pipelines using tools like Github actions and ArgoCD to deploy new versions of the application and cloud infrastructure. This way I could have multiple deployments (environments) of the application (ie testing, pre-prod, prod) and run automatically run tests against those environments as code is deployed to them (ie unittesting, integration testing, regression testing, security scanning, etc). Doing both SAST and DAST testing and keeping a shift left mentality.

** High Availability: ** The application would need to be highly available. Currently I am running it on multiple replicas in kubernetes, however it is only running on one local machine. For this service to be production ready we would want it to be deployed across multiple worker nodes in the cluster. This could be setup in our cloud deployment of the cluster. Ideally those would be in different availability zones for higher availability. And for even higher availability, and lower latency we can make our service to be multi region using DNS geo routing (ie with route53). We can also consider using a CDN (ie AWS Cloudfront) to help with this in serving static or frequently accessed content from edge locations.

** Security: ** I would also implement security best practices on both the kubernetes level as well as the infrastructure (ie cloud) level. On the k8s level I woukd use RBAC to control access to resources, and use secrets or external vaults (ie Ansible Vault) for sensitive data, and scanning containers for vulnerabilities. On the cloud level, assuming we use AWS, I would use tools such as AWS WAF to protect our application from security threats such as those in OWASP top 10 (ie DDOS) and more. We could also use AWS inspector to scan the worker nodes for security risks there. Other tools we can use include AWS KMS for encrypting data at rest (ie volumes in AWS EBS) and AWS secrets manager (for storing any secret values the app may need to call). There are many other security services in AWS worth considering using also such as AWS Guard Duty, AWS Macie, AWS Config, AWS security hub, etc. One other good security practice would be to scan the docker image for the application as part of our CI process before changes to it get merged.

** Monitoring and Logging: ** Before going to production it would also be crucial to set up monitoring and logging for the application to monitor its health, performance, and availability. I Use tools like Prometheus for metrics collection, Grafana for visualization. Fluentd or Elasticsearch would be options for log aggregation. If running on the AWS Cloud I would also utilize AWS Cloudwatch for Monitors, Metrics, logs, and alarms. AWS Cloudwatch Logs lets you aggregate logs, and AWS Monitors lets you create monitors based on your metrics and set thresholds for alarms to notify you or your team when something is wrong with the app. For the notification I could use AWS SNS, or another service called PagerDuty.

** Autoscaling: ** I'd also configure autoscaling at the k8s pod level and also the node level. This could be done with k8s replicasets, horizontal pod autoscaler, and metrics server for the application to automatically scale up or down based on resource usage metrics such as cpu utilization. This ensures that the application can handle varying levels of traffic without manual intervention. On the node level I would use something like AWS AutoScaling groups.

** Networking: ** As mentioned in the Reliable Hosting Infrastructure, and High Availability sections we'll want to make some changes to the networking components of this application before it goes live to prod.

** Disaster Recovery: ** Another important component for production will be to set up backups and disaster recovery plans for the application data, and infrastucture. Using persistent volumes for a stateful application such as EBS for data storage, and possibly a database if needed. Also backing up that data somewhere safe, and securite in case it somehow gets deleted. We would also want to backup the etcd data of the k8s cluster, possibly in an AWS S3 bucket. And as mentioned earlier having infrastructure as code in terraform would help us recover if any infrastructure resources were to somehow be destroyed or affected. We would also want to have documentation for restoring the service if a disaster does occur.

** Deployment Strategies: ** And as mentioned in the CI/CD pipelines section we should implement deployment strategies such as rolling updates or blue-green deployments to minimize downtime and ensure seamless updates to the application. I would also consider using helm charts or kustomize to manage k8s deployments across environments.
